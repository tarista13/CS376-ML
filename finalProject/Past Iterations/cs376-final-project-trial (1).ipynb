{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11384,"sourceType":"modelInstanceVersion","modelInstanceId":6216},{"sourceId":26140,"sourceType":"modelInstanceVersion","modelInstanceId":22003}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Who is working on this project\n\n(One person submits the document, other teammates just submit a note about who submitted the document.) Describe how you plan to work together so that everyone feels ownership of the result.","metadata":{}},{"cell_type":"markdown","source":"# Vision\nOverview of yoru project and its purpose. what are you trying to do? Why is it important or interesting? What does a successful project outcome look like?","metadata":{}},{"cell_type":"markdown","source":"# Background\nWhat data are you using? Describe what you chose and why. Include a “backup” dataset in case the primary one doesn’t work out (or give specific evidence for your confidence in the primary dataset).<br>\nWhat technologies are you using? Briefly describe a few options you’re considering and what criteria you’ll use to evaluate them.<br>\nYour final report will describe the technologies you’re using and why you chose to use them. Include citations of the work on which you’ve based your system, both what we’ve used in class and new technologies you’ve experimented with (include descriptions of these if applicable).","metadata":{}},{"cell_type":"markdown","source":"# Implementation\nWhat prior code can you build on?<br>\nYour final report will summarize your implementation and, if appropriate, how it extends the work you’ve reverenced.","metadata":{}},{"cell_type":"markdown","source":"# Prompt Engineering","metadata":{}},{"cell_type":"code","source":"import torch, os\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n# Work around a bug in the version of PyTorch and GPU hardware curretnly on Kaggle. On other hardware, removing these lines may lead to a speed-up.\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n# Load the model\nUSE_INSTRUCTION_TUNED = False # we'll switch this to True partway through the lab\nif USE_INSTRUCTION_TUNED:\n    model_name = '/kaggle/input/gemma/transformers/1.1-2b-it/1'\n    if not os.path.exists(model_name):\n        print(\"Warning: loading model weights from the Internet. This might take a bit of extra time.\")\n        model_name = \"google/gemma-1.1-2b-it\"\nelse:\n    model_name = \"/kaggle/input/gemma/transformers/2b/2\"\n    if not os.path.exists(model_name):\n        print(\"Warning: loading model weights from the Internet. This might take a bit of extra time.\")\n        model_name = \"google/gemma-2b\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map='auto',\n    torch_dtype=torch.bfloat16)\nstreamer = TextStreamer(tokenizer)\n# Silence a warning.\ntokenizer.decode([tokenizer.eos_token_id]);","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check where the whole model is loaded and what data type it's using.\nmodel.device, model.dtype","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:11:51.329189Z","iopub.execute_input":"2024-04-18T17:11:51.330575Z","iopub.status.idle":"2024-04-18T17:11:51.337908Z","shell.execute_reply.started":"2024-04-18T17:11:51.330535Z","shell.execute_reply":"2024-04-18T17:11:51.336710Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(device(type='cpu'), torch.bfloat16)"},"metadata":{}}]},{"cell_type":"code","source":"# Check where parameters are loaded. If this is anything other than {'': 0}\n# then probably some parts of the model got offloaded onto CPU and so will run slow.\nmodel.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:11:52.324378Z","iopub.execute_input":"2024-04-18T17:11:52.325510Z","iopub.status.idle":"2024-04-18T17:11:52.332247Z","shell.execute_reply.started":"2024-04-18T17:11:52.325470Z","shell.execute_reply":"2024-04-18T17:11:52.331263Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'': 'cpu'}"},"metadata":{}}]},{"cell_type":"code","source":"essay_prompt = '''In Homegoing, Pachinko, and Stories We Tell, the authors/filmmaker choose deliberate artistic strategies to present the histories they narrate. Discuss how the literary/filmic choices of Gyasi, Lee, and Polley are part of their overall theory about how the past should be constructed. In other words, how does the way in which they present their stories intersect with what they are trying to say in their stories? Are there commonalities in their aims? If so, what are they? Are there critical differences?'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:11:53.918551Z","iopub.execute_input":"2024-04-18T17:11:53.919133Z","iopub.status.idle":"2024-04-18T17:11:53.924174Z","shell.execute_reply.started":"2024-04-18T17:11:53.919104Z","shell.execute_reply":"2024-04-18T17:11:53.923016Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(essay_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:02.042834Z","iopub.execute_input":"2024-04-18T17:12:02.043489Z","iopub.status.idle":"2024-04-18T17:12:02.048283Z","shell.execute_reply.started":"2024-04-18T17:12:02.043457Z","shell.execute_reply":"2024-04-18T17:12:02.047119Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"In Homegoing, Pachinko, and Stories We Tell, the authors/filmmaker choose deliberate artistic strategies to present the histories they narrate. Discuss how the literary/filmic choices of Gyasi, Lee, and Polley are part of their overall theory about how the past should be constructed. In other words, how does the way in which they present their stories intersect with what they are trying to say in their stories? Are there commonalities in their aims? If so, what are they? Are there critical differences?\n","output_type":"stream"}]},{"cell_type":"code","source":"outline_first_paragraph = '''Please write me an introduction paragraph in essay format that follows this outline:\nThesis: Authors and filmmaker use multiple perspectives to illustrate how personal and ancestral choices shape individual narratives and identities, demonstrating their theories on how history should be constructed.\nBrief introduction of works and creators: Discusses Homegoing by Yaa Gyasi, Pachinko by Min Jin Lee, and Stories We Tell by Sarah Polley, setting the stage for an exploration of their narrative techniques.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:07.476938Z","iopub.execute_input":"2024-04-18T17:12:07.477323Z","iopub.status.idle":"2024-04-18T17:12:07.484507Z","shell.execute_reply.started":"2024-04-18T17:12:07.477294Z","shell.execute_reply":"2024-04-18T17:12:07.483215Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(outline_first_paragraph)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:17.067234Z","iopub.execute_input":"2024-04-18T17:12:17.068242Z","iopub.status.idle":"2024-04-18T17:12:17.074140Z","shell.execute_reply.started":"2024-04-18T17:12:17.068199Z","shell.execute_reply":"2024-04-18T17:12:17.072682Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Please write me an introduction paragraph in essay format that follows this outline:\nThesis: Authors and filmmaker use multiple perspectives to illustrate how personal and ancestral choices shape individual narratives and identities, demonstrating their theories on how history should be constructed.\nBrief introduction of works and creators: Discusses Homegoing by Yaa Gyasi, Pachinko by Min Jin Lee, and Stories We Tell by Sarah Polley, setting the stage for an exploration of their narrative techniques.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"outline_second_paragraph = '''Please write me my first supporting paragraph about personal choices shaping narratives in essay format that follows this outline:\nMain idea: Personal decisions directly shape characters' identities and futures in all three works, highlighting the authors' and filmmaker's focus on the impact of individual agency within broader historical and social contexts.\nExplanation: This exploration of personal choice aligns with the creators' views that history is not merely a series of events but a complex tapestry woven from individual actions and their consequences.\nExample from Pachinko: Sunja's pivotal decision to engage with Hansu, and its ramifications, showcase how personal mistakes and moral dilemmas are central to character development and plot progression.\nExample from Homegoing: The character H’s experience with forced labor and subsequent physical development illustrates how personal endurance and adaptation to circumstances reflect broader historical forces like slavery and institutional racism.\nExample from Stories We Tell: Harry’s narrative and his one-sided love affair demonstrate how personal perceptions can deeply influence one’s identity and the stories they choose to tell or believe.'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:34.033702Z","iopub.execute_input":"2024-04-18T17:12:34.034074Z","iopub.status.idle":"2024-04-18T17:12:34.039656Z","shell.execute_reply.started":"2024-04-18T17:12:34.034047Z","shell.execute_reply":"2024-04-18T17:12:34.038597Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(outline_second_paragraph)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:34.669399Z","iopub.execute_input":"2024-04-18T17:12:34.670388Z","iopub.status.idle":"2024-04-18T17:12:34.675778Z","shell.execute_reply.started":"2024-04-18T17:12:34.670352Z","shell.execute_reply":"2024-04-18T17:12:34.674667Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Please write me my first supporting paragraph about personal choices shaping narratives in essay format that follows this outline:\nMain idea: Personal decisions directly shape characters' identities and futures in all three works, highlighting the authors' and filmmaker's focus on the impact of individual agency within broader historical and social contexts.\nExplanation: This exploration of personal choice aligns with the creators' views that history is not merely a series of events but a complex tapestry woven from individual actions and their consequences.\nExample from Pachinko: Sunja's pivotal decision to engage with Hansu, and its ramifications, showcase how personal mistakes and moral dilemmas are central to character development and plot progression.\nExample from Homegoing: The character H’s experience with forced labor and subsequent physical development illustrates how personal endurance and adaptation to circumstances reflect broader historical forces like slavery and institutional racism.\nExample from Stories We Tell: Harry’s narrative and his one-sided love affair demonstrate how personal perceptions can deeply influence one’s identity and the stories they choose to tell or believe.\n","output_type":"stream"}]},{"cell_type":"code","source":"outline_third_paragraph = '''Please write me my second supporting paragraph about influence of others and ancestors in essay format that follows this outline:\nMain idea: Characters’ identities and life paths are significantly influenced by the actions and statuses of those around them and their ancestors, emphasizing the interconnectedness of personal histories within larger societal narratives.\nExplanation: This theme underscores the authors' and filmmaker's perspective that individual lives are not isolated but are deeply affected by the historical and relational contexts in which they exist, echoing a broader theory that history is constructed collectively rather than singularly.\nExample from Pachinko: Isak’s altruistic decision to marry Sunja provides a stark contrast to her initial dilemma, showing how benevolent actions from others can redirect an individual’s life trajectory dramatically.\nExample from Homegoing: The legacy of slavery, as seen through Esi and her descendant Ness, highlights how ancestral histories cast long shadows over the lives of future generations, shaping identities and opportunities long after the original events have passed.\nExample from Stories We Tell: The revelation of Sarah’s true paternity and Diane’s decisions regarding her upbringing illustrate the profound impact parental choices have on children’s identities and their understanding of family narratives.'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:36.651697Z","iopub.execute_input":"2024-04-18T17:12:36.652058Z","iopub.status.idle":"2024-04-18T17:12:36.656980Z","shell.execute_reply.started":"2024-04-18T17:12:36.652032Z","shell.execute_reply":"2024-04-18T17:12:36.656102Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(outline_third_paragraph)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:44.742322Z","iopub.execute_input":"2024-04-18T17:12:44.742748Z","iopub.status.idle":"2024-04-18T17:12:44.747826Z","shell.execute_reply.started":"2024-04-18T17:12:44.742717Z","shell.execute_reply":"2024-04-18T17:12:44.746732Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Please write me my second supporting paragraph about influence of others and ancestors in essay format that follows this outline:\nMain idea: Characters’ identities and life paths are significantly influenced by the actions and statuses of those around them and their ancestors, emphasizing the interconnectedness of personal histories within larger societal narratives.\nExplanation: This theme underscores the authors' and filmmaker's perspective that individual lives are not isolated but are deeply affected by the historical and relational contexts in which they exist, echoing a broader theory that history is constructed collectively rather than singularly.\nExample from Pachinko: Isak’s altruistic decision to marry Sunja provides a stark contrast to her initial dilemma, showing how benevolent actions from others can redirect an individual’s life trajectory dramatically.\nExample from Homegoing: The legacy of slavery, as seen through Esi and her descendant Ness, highlights how ancestral histories cast long shadows over the lives of future generations, shaping identities and opportunities long after the original events have passed.\nExample from Stories We Tell: The revelation of Sarah’s true paternity and Diane’s decisions regarding her upbringing illustrate the profound impact parental choices have on children’s identities and their understanding of family narratives.\n","output_type":"stream"}]},{"cell_type":"code","source":"human_essay_first_paragraph = '''Many people believe that there is only one story going on in the world, and they are the main characters. They believe that everything should revolve around them, and everybody else in this world is a small side character. We often don't think that there are billions of different stories happening all at the same time, which can then affect our narratives through their perspectives. The authors and filmmakers of Homegoing, Pachinko, and Stories We Tell, use the perspective of many people in similar situations to demonstrate how the narratives of people’s lives can be shaped and defined by the choices they make personally, and the people around them including their ancestors. '''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:51.597468Z","iopub.execute_input":"2024-04-18T17:12:51.597860Z","iopub.status.idle":"2024-04-18T17:12:51.603266Z","shell.execute_reply.started":"2024-04-18T17:12:51.597806Z","shell.execute_reply":"2024-04-18T17:12:51.601974Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(human_essay_first_paragraph)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:12:59.187217Z","iopub.execute_input":"2024-04-18T17:12:59.187658Z","iopub.status.idle":"2024-04-18T17:12:59.192630Z","shell.execute_reply.started":"2024-04-18T17:12:59.187623Z","shell.execute_reply":"2024-04-18T17:12:59.191389Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Many people believe that there is only one story going on in the world, and they are the main characters. They believe that everything should revolve around them, and everybody else in this world is a small side character. We often don't think that there are billions of different stories happening all at the same time, which can then affect our narratives through their perspectives. The authors and filmmakers of Homegoing, Pachinko, and Stories We Tell, use the perspective of many people in similar situations to demonstrate how the narratives of people’s lives can be shaped and defined by the choices they make personally, and the people around them including their ancestors. \n","output_type":"stream"}]},{"cell_type":"code","source":"human_essay_second_paragraph = '''People’s identities are often defined by the choices they made in the past, whether they are successful or unsuccessful, honorable or dishonorable. The authors and filmmakers of these stories demonstrate how a person’s choices can shape their narratives. In the novel, Pachinko by Min Jin Lee, we mainly see the story through the viewpoint of Sunja, but we will occasionally get to look through or see the thoughts of the people close to her. In the novel, it states, “If he did not marry her, she was a common slut who would be disgraced forever. The child would be another no-name bastard. Her mother’s boardinghouse would be contaminated by her shame”(Lee 49). Sunja made a big mistake by being with Hansu, and she paid the price. She was now pregnant, and the father of the child won’t be able to marry her because he is already married. In her society, bearing a child without a father will lead to having the mother, in this case, Sunja, be disowned. It could also lead to her family and her child being disowned as well. Looking through the lens of Sunja, we could see how devastated she was and the impact her decisions could make on her in the future. Also, in the novel, Homegoing by Yaa Gyasi, we see through many different lenses in many different generations. In the chapter about H, it states, “The boss man was called Mr. John. He asked to take off his shirt. He inspected the muscles on his back and his arms and whistled. ‘Any man what can spend ten years working at Rock Slope and live to tell about it’s worth watching”(Gyasi 169). When H was sent to me while he was arrested, he might not have had an option on whether or not he wanted to work, but it made him better in the long run. He had gotten physically strong, and when he had gotten released, he was able to find a mining job that paid him. The situation he was put in shaped the person that H was. He became a hard worker and he made sure he did his job. Those were some of the things that he learned while he mined for the jail, but he was able to apply those lessons to the real world and shaped him to be somebody that was hirable. Another example of identities being defined by self choices is in the documentary, Stories We Tell, produced by Sarah Polley. When Harry met with Diane when she traveled to Montreal for a play, Harry fell in love with her. He had his own one-sided story, where he thought he was going to be with Diane for the rest of his life. This ultimately shaped his identity for the future. At the end of the documentary, Sarah asked Harry whether he liked that many people are sharing their sides of the story or if he disliked it. He shared that he did not like how many people shared their sides because he thought it was only his story to tell. He got wrapped up in the sense that Diane only loved him, and that changed the way he viewed his story.'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:13:00.720672Z","iopub.execute_input":"2024-04-18T17:13:00.721071Z","iopub.status.idle":"2024-04-18T17:13:00.727453Z","shell.execute_reply.started":"2024-04-18T17:13:00.721041Z","shell.execute_reply":"2024-04-18T17:13:00.726257Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(human_essay_second_paragraph)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:13:10.134196Z","iopub.execute_input":"2024-04-18T17:13:10.134636Z","iopub.status.idle":"2024-04-18T17:13:10.140249Z","shell.execute_reply.started":"2024-04-18T17:13:10.134604Z","shell.execute_reply":"2024-04-18T17:13:10.139330Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"People’s identities are often defined by the choices they made in the past, whether they are successful or unsuccessful, honorable or dishonorable. The authors and filmmakers of these stories demonstrate how a person’s choices can shape their narratives. In the novel, Pachinko by Min Jin Lee, we mainly see the story through the viewpoint of Sunja, but we will occasionally get to look through or see the thoughts of the people close to her. In the novel, it states, “If he did not marry her, she was a common slut who would be disgraced forever. The child would be another no-name bastard. Her mother’s boardinghouse would be contaminated by her shame”(Lee 49). Sunja made a big mistake by being with Hansu, and she paid the price. She was now pregnant, and the father of the child won’t be able to marry her because he is already married. In her society, bearing a child without a father will lead to having the mother, in this case, Sunja, be disowned. It could also lead to her family and her child being disowned as well. Looking through the lens of Sunja, we could see how devastated she was and the impact her decisions could make on her in the future. Also, in the novel, Homegoing by Yaa Gyasi, we see through many different lenses in many different generations. In the chapter about H, it states, “The boss man was called Mr. John. He asked to take off his shirt. He inspected the muscles on his back and his arms and whistled. ‘Any man what can spend ten years working at Rock Slope and live to tell about it’s worth watching”(Gyasi 169). When H was sent to me while he was arrested, he might not have had an option on whether or not he wanted to work, but it made him better in the long run. He had gotten physically strong, and when he had gotten released, he was able to find a mining job that paid him. The situation he was put in shaped the person that H was. He became a hard worker and he made sure he did his job. Those were some of the things that he learned while he mined for the jail, but he was able to apply those lessons to the real world and shaped him to be somebody that was hirable. Another example of identities being defined by self choices is in the documentary, Stories We Tell, produced by Sarah Polley. When Harry met with Diane when she traveled to Montreal for a play, Harry fell in love with her. He had his own one-sided story, where he thought he was going to be with Diane for the rest of his life. This ultimately shaped his identity for the future. At the end of the documentary, Sarah asked Harry whether he liked that many people are sharing their sides of the story or if he disliked it. He shared that he did not like how many people shared their sides because he thought it was only his story to tell. He got wrapped up in the sense that Diane only loved him, and that changed the way he viewed his story.\n","output_type":"stream"}]},{"cell_type":"code","source":"human_essay_third_paragraph = '''While some believe that their identity is solely based on their choices, people’s identities can be altered by the people around them and by their ancestors. When we start looking through the other lenses of people in the same situation, we can see that many times the expected outcome is different from reality. In the novel, Pachinko, it states, “‘Of course it would be far better for them if she went away’ Yangjin replied, knowing the hard truth. ‘The child would have a terrible life here. You’d be saving my daughter’s life as well'”(Lee 74). Isak knew the dilemma Sunja was in and he knew this was something that shouldn’t be taken lightly. After coming up with the idea of marrying Sunja and giving the child his last name, he had lifted the burden off Sunja and her child’s back. They would no longer have to bear the weight of being dishonored by society and her family. Having people who can have a different perspective of the matter, can allow one to alter the course of somebody. Then, in the novel, Homegoing, we were able to witness the identities being altered because of their past relatives. In the novel, it states, “Every day, Ness picked cotton under the punishing eye of the southern sun. She had been at Thomas Allan Stockham’s Alabama plantation for three months”(Gyasi 70). Ness was a descendant of Esi in this story. Esi was a part of the slave trade system and her life was very rough. Esi went through an enormous amount of abuse and unbearable situations. Since being in that slave system, it had affected the rest of her family tree. Ness is the daughter of Esi, and so, Ness had to bear the identity of being a slave just like her mother. She had to be a slave on a plantation and no choice she made would be able to change that in this system. Her identity at the time was determined by her mother and how she was a part of the system. Lastly, in the documentary, Stories We Tell, Sarah’s identity was shaped by the choices her mother made when she was alive. Sarah never knew that Michael was not her biological father until she grew up. Sarah was able to form a strong bond with Michael, and that was because Diane decided to have Michael take care of her instead of Harry. Once Sarah found out that Harry was her father, Sarah was still able to keep the close relationship with Michael even after finding out the truth. Sarah was able to keep her identity from the one she formed with Michael, and that was all due to Diane.'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:13:12.151656Z","iopub.execute_input":"2024-04-18T17:13:12.152047Z","iopub.status.idle":"2024-04-18T17:13:12.158321Z","shell.execute_reply.started":"2024-04-18T17:13:12.152017Z","shell.execute_reply":"2024-04-18T17:13:12.157160Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(human_essay_third_paragraph)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:13:21.940410Z","iopub.execute_input":"2024-04-18T17:13:21.940826Z","iopub.status.idle":"2024-04-18T17:13:21.945777Z","shell.execute_reply.started":"2024-04-18T17:13:21.940797Z","shell.execute_reply":"2024-04-18T17:13:21.944942Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"While some believe that their identity is solely based on their choices, people’s identities can be altered by the people around them and by their ancestors. When we start looking through the other lenses of people in the same situation, we can see that many times the expected outcome is different from reality. In the novel, Pachinko, it states, “‘Of course it would be far better for them if she went away’ Yangjin replied, knowing the hard truth. ‘The child would have a terrible life here. You’d be saving my daughter’s life as well'”(Lee 74). Isak knew the dilemma Sunja was in and he knew this was something that shouldn’t be taken lightly. After coming up with the idea of marrying Sunja and giving the child his last name, he had lifted the burden off Sunja and her child’s back. They would no longer have to bear the weight of being dishonored by society and her family. Having people who can have a different perspective of the matter, can allow one to alter the course of somebody. Then, in the novel, Homegoing, we were able to witness the identities being altered because of their past relatives. In the novel, it states, “Every day, Ness picked cotton under the punishing eye of the southern sun. She had been at Thomas Allan Stockham’s Alabama plantation for three months”(Gyasi 70). Ness was a descendant of Esi in this story. Esi was a part of the slave trade system and her life was very rough. Esi went through an enormous amount of abuse and unbearable situations. Since being in that slave system, it had affected the rest of her family tree. Ness is the daughter of Esi, and so, Ness had to bear the identity of being a slave just like her mother. She had to be a slave on a plantation and no choice she made would be able to change that in this system. Her identity at the time was determined by her mother and how she was a part of the system. Lastly, in the documentary, Stories We Tell, Sarah’s identity was shaped by the choices her mother made when she was alive. Sarah never knew that Michael was not her biological father until she grew up. Sarah was able to form a strong bond with Michael, and that was because Diane decided to have Michael take care of her instead of Harry. Once Sarah found out that Harry was her father, Sarah was still able to keep the close relationship with Michael even after finding out the truth. Sarah was able to keep her identity from the one she formed with Michael, and that was all due to Diane.\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\ndef generate_and_analyze(outline, essay):\n    # Generate text based on the outline\n    model_input = tokenizer.encode(outline, return_tensors='pt').to(model.device)\n    generated_output = model.generate(model_input, max_length=512, num_return_sequences=1)\n    generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n    \n    # Tokenize the generated text and the human essay for comparison\n    gen_ids = tokenizer.encode(generated_text, return_tensors='pt').to(model.device)\n    essay_ids = tokenizer.encode(essay, return_tensors='pt').to(model.device)\n    \n    # Concatenate tokens for analysis\n    input_ids = torch.cat([gen_ids, essay_ids[:, 1:]], dim=-1)\n    \n    # Generate logits for concatenated input\n    with torch.no_grad():\n        outputs = model(input_ids)\n        logits = outputs.logits\n    \n    # Analyze tokens for loss\n    # Analyze tokens for loss\n    spans = []\n    highest_loss = float('-inf')\n    softmax = torch.nn.Softmax(dim=-1)\n    essay_tokens = tokenizer.convert_ids_to_tokens(essay_ids[0])\n\n    for i in range(gen_ids.size(1), input_ids.size(1)):\n        probs = softmax(logits[0, i - 1])\n        token_loss = -torch.log(probs[input_ids[0, i]]).item()\n        most_likely_token_id = torch.argmax(probs).item()\n        token = essay_tokens[i - gen_ids.size(1) + 1]  # Adjust index for essay tokens\n        most_likely_token = tokenizer.decode([most_likely_token_id])\n    \n        spans.append({\n            'original_token': token,\n            'token_loss': token_loss,\n            'most_likely_token': most_likely_token,\n            'loss_ratio': None  # Will be calculated below\n        })\n        if token_loss > highest_loss:\n            highest_loss = token_loss\n\n    # Normalize loss ratios\n    for span in spans:\n        span['loss_ratio'] = span['token_loss'] / highest_loss\n\n    \n    df = pd.DataFrame(spans)\n    return {\n        'outline': outline,\n        'generated_text': generated_text,\n        'analysis_df': df\n    }\n'''","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:44:19.501394Z","iopub.execute_input":"2024-04-18T16:44:19.502436Z","iopub.status.idle":"2024-04-18T16:44:19.514031Z","shell.execute_reply.started":"2024-04-18T16:44:19.502379Z","shell.execute_reply":"2024-04-18T16:44:19.512747Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"\"\\ndef generate_and_analyze(outline, essay):\\n    # Generate text based on the outline\\n    model_input = tokenizer.encode(outline, return_tensors='pt').to(model.device)\\n    generated_output = model.generate(model_input, max_length=512, num_return_sequences=1)\\n    generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\\n    \\n    # Tokenize the generated text and the human essay for comparison\\n    gen_ids = tokenizer.encode(generated_text, return_tensors='pt').to(model.device)\\n    essay_ids = tokenizer.encode(essay, return_tensors='pt').to(model.device)\\n    \\n    # Concatenate tokens for analysis\\n    input_ids = torch.cat([gen_ids, essay_ids[:, 1:]], dim=-1)\\n    \\n    # Generate logits for concatenated input\\n    with torch.no_grad():\\n        outputs = model(input_ids)\\n        logits = outputs.logits\\n    \\n    # Analyze tokens for loss\\n    # Analyze tokens for loss\\n    spans = []\\n    highest_loss = float('-inf')\\n    softmax = torch.nn.Softmax(dim=-1)\\n    essay_tokens = tokenizer.convert_ids_to_tokens(essay_ids[0])\\n\\n    for i in range(gen_ids.size(1), input_ids.size(1)):\\n        probs = softmax(logits[0, i - 1])\\n        token_loss = -torch.log(probs[input_ids[0, i]]).item()\\n        most_likely_token_id = torch.argmax(probs).item()\\n        token = essay_tokens[i - gen_ids.size(1) + 1]  # Adjust index for essay tokens\\n        most_likely_token = tokenizer.decode([most_likely_token_id])\\n    \\n        spans.append({\\n            'original_token': token,\\n            'token_loss': token_loss,\\n            'most_likely_token': most_likely_token,\\n            'loss_ratio': None  # Will be calculated below\\n        })\\n        if token_loss > highest_loss:\\n            highest_loss = token_loss\\n\\n    # Normalize loss ratios\\n    for span in spans:\\n        span['loss_ratio'] = span['token_loss'] / highest_loss\\n\\n    \\n    df = pd.DataFrame(spans)\\n    return {\\n        'outline': outline,\\n        'generated_text': generated_text,\\n        'analysis_df': df\\n    }\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"# Trial by just providing the outline and human written essay","metadata":{}},{"cell_type":"code","source":"def generate_text(outline):\n    # Encode the outline and generate text\n    model_input = tokenizer.encode(outline, return_tensors='pt').to(model.device)\n    generated_output = model.generate(model_input, max_length=512, num_return_sequences=1)\n    generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n    \n    # Tokenize the generated text for analysis\n    gen_ids = tokenizer.encode(generated_text, return_tensors='pt').to(model.device)\n    \n    return generated_text, gen_ids","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:25:59.898713Z","iopub.execute_input":"2024-04-18T17:25:59.899090Z","iopub.status.idle":"2024-04-18T17:25:59.904881Z","shell.execute_reply.started":"2024-04-18T17:25:59.899063Z","shell.execute_reply":"2024-04-18T17:25:59.903696Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def analyze_text(generated_ids, essay):\n    # Tokenize the essay for comparison\n    essay_ids = tokenizer.encode(essay, return_tensors='pt').to(model.device)\n    \n    # Concatenate tokens for analysis\n    input_ids = torch.cat([generated_ids, essay_ids[:, 1:]], dim=-1)\n    \n    # Generate logits for concatenated input\n    with torch.no_grad():\n        outputs = model(input_ids)\n        logits = outputs.logits\n    \n    # Analyze tokens for loss\n    spans = []\n    highest_loss = float('-inf')\n    softmax = torch.nn.Softmax(dim=-1)\n    essay_tokens = tokenizer.convert_ids_to_tokens(essay_ids[0])\n    \n    for i in range(generated_ids.size(1), input_ids.size(1)):\n        probs = softmax(logits[0, i - 1])\n        token_loss = -torch.log(probs[input_ids[0, i]]).item()\n        most_likely_token_id = torch.argmax(probs).item()\n        token = essay_tokens[i - generated_ids.size(1) + 1]  # Adjust index for essay tokens\n        most_likely_token = tokenizer.decode([most_likely_token_id])\n        \n        spans.append({\n            'original_token': token,\n            'token_loss': token_loss,\n            'most_likely_token': most_likely_token,\n            'loss_ratio': None  # To be calculated later\n        })\n        \n        if token_loss > highest_loss:\n            highest_loss = token_loss\n\n    # Normalize loss ratios\n    for span in spans:\n        span['loss_ratio'] = span['token_loss'] / highest_loss\n\n    df = pd.DataFrame(spans)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:26:02.286390Z","iopub.execute_input":"2024-04-18T17:26:02.287012Z","iopub.status.idle":"2024-04-18T17:26:02.296656Z","shell.execute_reply.started":"2024-04-18T17:26:02.286978Z","shell.execute_reply":"2024-04-18T17:26:02.295255Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"outline = outline_first_paragraph\nessay = human_essay_first_paragraph\n\n# Generate text based on the outline\ngenerated_text, generated_ids = generate_text(outline)\n\n# Analyze the generated text against the provided essay\nanalysis_df = analyze_text(generated_ids, essay)\n\n# Display results\nprint(\"Generated Essay:\", generated_text)\nprint(\"\\nAnalysis:\")\ndisplay(analysis_df[['original_token', 'token_loss', 'most_likely_token', 'loss_ratio']])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:26:10.580119Z","iopub.execute_input":"2024-04-18T17:26:10.580583Z","iopub.status.idle":"2024-04-18T17:29:38.740732Z","shell.execute_reply.started":"2024-04-18T17:26:10.580552Z","shell.execute_reply":"2024-04-18T17:29:38.738976Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m essay \u001b[38;5;241m=\u001b[39m human_essay_first_paragraph\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate text based on the outline\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m generated_text, generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Analyze the generated text against the provided essay\u001b[39;00m\n\u001b[1;32m      8\u001b[0m analysis_df \u001b[38;5;241m=\u001b[39m analyze_text(generated_ids, essay)\n","Cell \u001b[0;32mIn[29], line 4\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(outline)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_text\u001b[39m(outline):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Encode the outline and generate text\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     model_input \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(outline, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m----> 4\u001b[0m     generated_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Tokenize the generated text for analysis\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1527\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1524\u001b[0m     )\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2411\u001b[0m, in \u001b[0;36mGenerationMixin._greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2411\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2419\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:1105\u001b[0m, in \u001b[0;36mGemmaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1102\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1119\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:923\u001b[0m, in \u001b[0;36mGemmaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m         cache_position,\n\u001b[1;32m    921\u001b[0m     )\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:658\u001b[0m, in \u001b[0;36mGemmaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 658\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    661\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:189\u001b[0m, in \u001b[0;36mGemmaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def rewrite_essay(analysis_df, essay_text):\n    # Tokenize the original essay text\n    essay_ids = tokenizer.encode(essay_text, return_tensors='pt').to(model.device)\n    essay_tokens = tokenizer.convert_ids_to_tokens(essay_ids[0])\n\n    # Create a new list to hold the rewritten essay tokens\n    rewritten_tokens = []\n    \n    for idx, row in analysis_df.iterrows():\n        # Ensure index alignment with essay tokens\n        if idx < len(essay_tokens):\n            # Replace the token if the loss ratio is above a certain threshold\n            if row['loss_ratio'] > 0.5:  # This threshold can be adjusted\n                rewritten_tokens.append(row['most_likely_token'])\n            else:\n                rewritten_tokens.append(row['original_token'])\n\n    # Join the tokens back into a single string using the tokenizer to ensure correct spacing\n    rewritten_essay = tokenizer.convert_tokens_to_string(rewritten_tokens)\n    return rewritten_essay","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:25:42.983312Z","iopub.status.idle":"2024-04-18T17:25:42.983748Z","shell.execute_reply.started":"2024-04-18T17:25:42.983551Z","shell.execute_reply":"2024-04-18T17:25:42.983568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original Essay:\", essay)\nprint(\"Generated Essay:\", generated_text)\nprint(\"Rewritten Essay:\", rewritten_essay)\nprint(\"\\nAnalysis:\")\ndisplay(analysis_df[['original_token', 'token_loss', 'most_likely_token', 'loss_ratio']])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:22:21.674144Z","iopub.status.idle":"2024-04-18T17:22:21.674564Z","shell.execute_reply.started":"2024-04-18T17:22:21.674358Z","shell.execute_reply":"2024-04-18T17:22:21.674374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def highlight_replacements(analysis_df, essay_text):\n    # Tokenize the original essay text\n    essay_ids = tokenizer.encode(essay_text, return_tensors='pt').to(model.device)\n    essay_tokens = tokenizer.convert_ids_to_tokens(essay_ids[0])\n\n    replacements = []\n    \n    # Check for replacements in the analysis dataframe\n    for idx, row in analysis_df.iterrows():\n        if idx < len(essay_tokens):\n            original_token = row['original_token']\n            replacement_token = row['most_likely_token']\n            \n            # Check if replacement is different and loss ratio is above threshold\n            if original_token != replacement_token and row['loss_ratio'] > 0.5:\n                replacements.append((original_token, replacement_token))\n    \n    return replacements","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:22:21.676586Z","iopub.status.idle":"2024-04-18T17:22:21.676987Z","shell.execute_reply.started":"2024-04-18T17:22:21.676805Z","shell.execute_reply":"2024-04-18T17:22:21.676820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outline = outline_first_paragraph\nessay = human_essay_first_paragraph\ngenerated_text, generated_ids = generate_text(outline)\nanalysis_df = analyze_text(generated_ids, essay)\n\n# Get the list of replacements\nreplacements = highlight_replacements(analysis_df, essay)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:22:21.678484Z","iopub.status.idle":"2024-04-18T17:22:21.678863Z","shell.execute_reply.started":"2024-04-18T17:22:21.678692Z","shell.execute_reply":"2024-04-18T17:22:21.678707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original Essay:\", essay)\nprint(\"Rewritten Essay:\", rewritten_essay)\nprint(\"\\nReplacements:\")\nfor original, replaced in replacements:\n    print(f\"Original: '{original}' was replaced with '{replaced}'\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:22:21.680095Z","iopub.status.idle":"2024-04-18T17:22:21.680728Z","shell.execute_reply.started":"2024-04-18T17:22:21.680545Z","shell.execute_reply":"2024-04-18T17:22:21.680561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trial by including the prompt","metadata":{}},{"cell_type":"code","source":"def generate_text_with_prompt(prompt, outline):\n    full_input = prompt + \" \" + outline\n    model_input_with_prompt = tokenizer.encode(full_input, return_tensors='pt').to(model.device)\n    generated_output_with_prompt = model.generate(model_input, max_length=512, num_return_sequence=1)\n    generated_text_with_prompt = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n    \n    gen_ids_with_prompt = tokenizer.encode(generated_text, return_tensors='pt').to(model.device)\n    \n    return generated_text_with_prompt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def analyze_text_with_prompt(generated_ids, essay):\n    essay_ids_with_prompt = tokenizer.encode(essay, return_tensors='pt').to(model.device)\n    input_ids = torch.cat([generated_ids, essay_ids[:, 1:]], dim=-1)\n    \n    with torch.no_grad():\n        outputs = model(input_ids)\n        logits = output.logits\n        \n    spans = []\n    highest_loss = float('-inf')\n    softmax = torch.nn.Softmax(dim=-1)\n    essay_tokens = tokenizer.convert_ids_to_tokens(essay_ids[0])\n    \n    for i in range(generated_ids.size(1), input_ids.size(1)):\n        probs = softmax(logits[0, i-1])\n        token_loss = -torch.log(probs[input_ids[0,i]]).item()\n        most_likely_token_id = torch.argmax(probs).item()\n        token = essay_tokens[i - generated_ids.size(1) + 1]\n        most_likely_token = tokenizer.decode([most_likely_token_id])\n        \n        spans.append({\n            'original_token' : token,\n            'token_loss' : token_loss,\n            'most_likely_token' : most_likely_token,\n            'loss_ratio' : None\n        })\n        \n        if token_loss > highest_loss:\n            highest_loss = token_loss\n        \n        for span in spans:\n            span['loss ratio'] = span['token_loss'] / highest_loss\n            \n        return pd.DataFrame(spans)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = prompt\noutline = outline_first_paragraph\nessay = human_essay_first_paragraph\n\ngenerated_text, generated_ids = generate_text_with_prompt(prompt, outline)\nanalysis_df = analyze_text_with_prompt(generated_ids, essay)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Prompt:\", prompt)\nprint(\"Original Essay:\", essay)\nprint(\"\\nGenerated Essay:\", generated_text)\nprint(\"\\nRewritten Essay:\", rewritten_essay)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results\n Include quantitative (tables, plots) and qualitative (examples) results, including comparisons with similar work if applicable.","metadata":{}},{"cell_type":"markdown","source":"# Implications\nDiscuss the social and ethical implications of using the technologies you’ve chosen for your project.","metadata":{}}]}